{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6282f787",
   "metadata": {},
   "source": [
    "## EXPLORE Data Science Academy Classification Hackathon\n",
    "### Overview\n",
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "From South African Government\n",
    "\n",
    "This has prompted the need to get a model that can classify the different languages based on the text from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1da8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for data analysis\n",
    "import numpy as np                     \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "# Customise our plotting settings\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "#Libraries for data cleaning and preprocessing\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "#Libraries for data preparation and model building\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Libraries for test of model performance\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c81d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training and test data set\n",
    "df_train = pd.read_csv('train_set.csv')\n",
    "df_test = pd.read_csv('test_set.csv')\n",
    "df_sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3991d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe15577",
   "metadata": {},
   "source": [
    "## Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abe230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a copy of the train dataset\n",
    "df = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff487b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for the data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for unbalanced data\n",
    "df['lang_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46f6cd",
   "metadata": {},
   "source": [
    "From the above cell, values show that all the data in different class labels are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the distribution of unique label values\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.countplot(x=\"lang_id\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function that cleans the data\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function uses regular expressions to remove html characters,\n",
    "    punctuation, numbers and any extra white space from each text\n",
    "    and then converts them to lowercase.\n",
    "\n",
    "    Input:\n",
    "    text: original text\n",
    "          datatype: string\n",
    "\n",
    "    Output:\n",
    "    texts: modified text\n",
    "           datatype: string\n",
    "    \"\"\"\n",
    "    # replace the html characters with \" \"\n",
    "    text=re.sub('<.*?>', ' ', text)\n",
    "#     Removal of numbers\n",
    "#    text = re.sub(r'\\d+', ' ', text)\n",
    "    # will replace newline with space\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    # will convert to lower case\n",
    "    text = text.lower()\n",
    "    # will split and join the words\n",
    "    text=' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of the function to clean the text column\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '.txt' with 'text file'\n",
    "df[\"text\"] = df[\"text\"].str.replace(\".txt\", \" text file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbe178",
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7559816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further Data preprocessing\n",
    "#function that handles the removal punctuations from the dataset\n",
    "def remove_punct(text):\n",
    "    \"\"\"\n",
    "    the function remove_punction, it takes in a text as input and loops through\n",
    "    the text, if a character is not in string.punctuation then it adds the character\n",
    "    as a string to the text variable\n",
    "    \n",
    "    \"\"\"\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the remve_puct func to the tweets column\n",
    "df['text'] = df['text'].apply(lambda x: remove_punct(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8850707",
   "metadata": {},
   "source": [
    "### Applying same for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9db882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a copy of the test dataset\n",
    "test_df = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957eca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27af662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the cleaning process on the test dataset\n",
    "test_df['text'] = test_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing any .txt file to text file\n",
    "test_df[\"text\"] = test_df[\"text\"].str.replace(\".txt\", \" text file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the x features\n",
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8585fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the label(str) to a code\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "#Fit label encoder and return encoded labels\n",
    "y = le.fit_transform(df['lang_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the labels to a list\n",
    "type_labels = (le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dfb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validation data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating different models to be deployed\n",
    "\"\"\"\n",
    "Note: Some classifiers were commented out because\n",
    "they run for a very long time, \n",
    "\"\"\"\n",
    "classifiers = [LogisticRegression(random_state=42,\n",
    "                                  multi_class='ovr',\n",
    "                                  n_jobs=1,\n",
    "                                  C=1e5,\n",
    "                                  max_iter=4000),\n",
    "               KNeighborsClassifier(n_neighbors=5),\n",
    "               MultinomialNB(),\n",
    "               ComplementNB(),\n",
    "               SGDClassifier(loss='hinge',\n",
    "                             penalty='l2',\n",
    "                             alpha=1e-3,\n",
    "                             random_state=42,\n",
    "                             max_iter=5,\n",
    "                             tol=None)\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class of model classifiers and performance\n",
    "def classifier_models(classifiers, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This function takes in a list of classifiers\n",
    "    and both the train and validation sets\n",
    "    and return a summary of F1-score and\n",
    "    processing time as a dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    model_summary = {}\n",
    "\n",
    "    # Pipeline to balance the classses and then to build the model\n",
    "    for clf in classifiers:\n",
    "        clf_text = Pipeline([('tfidf', TfidfVectorizer(min_df=1,\n",
    "                                                       max_df=0.9,\n",
    "                                                       ngram_range=(1, 1))),\n",
    "                             ('clf', clf)])\n",
    "\n",
    "        # Logging the Execution Time for each model\n",
    "        start_time = time.time()\n",
    "        clf_text.fit(X_train, y_train)\n",
    "        predictions = clf_text.predict(X_test)\n",
    "        run_time = time.time()-start_time\n",
    "\n",
    "        # performance of  each model\n",
    "        model_summary[clf.__class__.__name__] = {\n",
    "            'F1-Macro': metrics.f1_score(y_test,\n",
    "                                         predictions,\n",
    "                                         average='macro'),\n",
    "            'F1-Accuracy': metrics.f1_score(y_test, predictions,\n",
    "                                            average='micro'),\n",
    "            'F1-Weighted': metrics.f1_score(y_test,\n",
    "                                            predictions,\n",
    "                                            average='weighted'),\n",
    "            'Execution Time': run_time}\n",
    "\n",
    "    return pd.DataFrame.from_dict(model_summary, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_df = classifier_models(classifiers, X_train, y_train, X_test, y_test)\n",
    "Order_of_performance = classifiers_df.sort_values('F1-Macro', ascending=False)\n",
    "Order_of_performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline for the gridsearch\n",
    "param_grid = {'alpha': [0.1, 1, 5, 10, 100]}  # setting parameter grid\n",
    "\n",
    "modified_mnb = Pipeline([('tfidf', TfidfVectorizer(min_df=1,\n",
    "                                                max_df=0.9,\n",
    "                                                ngram_range=(1, 2))),\n",
    "                      ('mnb', GridSearchCV(MultinomialNB(),\n",
    "                                           param_grid=param_grid,\n",
    "                                           cv=5,\n",
    "                                           n_jobs=-1,\n",
    "                                           scoring='f1_weighted'))\n",
    "                      ])\n",
    "\n",
    "modified_mnb.fit(X_train, y_train)  # model fitting\n",
    "\n",
    "y_mnb = modified_mnb.predict(X_test)  # predicting the fit on validation set\n",
    "\n",
    "print(classification_report(y_test, y_mnb,  target_names = type_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on the test dataset\n",
    "prediction3 = modified_mnb.predict(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving in a submission csv file\n",
    "submission_df5 = pd.DataFrame(test_df['index'])\n",
    "submission_df5['lang_id'] = le.inverse_transform(prediction3)\n",
    "submission_df5.to_csv('submission_modified_mnb2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a209c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc88367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
